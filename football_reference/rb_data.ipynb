{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import urllib\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########  THIS BLOCK OF CODE IS DEVELOPMENT CODE, NEEDS TO BE WORKED ON\n",
    "########\n",
    "\n",
    "# base = ('http://www.pro-football-reference.com/play-index/psl_finder.cgi?request=1&match=single&year_min=1999&year_max=2016&season_start=1&season_end=-1&age_min=0&age_max=99&league_id=NFL&team_id=&is_active=&is_hof=&pos_is_rb=Y&c1stat=height_in&c1comp=gt&c1val=&c2stat=fumbles_rec&c2comp=gt&c2val=&c3stat=seasons&c3comp=gt&c3val=&c4stat=rush_att&c4comp=gt&c4val=&c5comp=&c5gtlt=lt&c6mult=1.0&c6comp=&order_by=year_id&draft=0&draft_year_min=1936&draft_year_max=2016&type=&draft_round_min=0&draft_round_max=99&draft_slot_min=1&draft_slot_max=500&draft_pick_in_round=0&draft_league_id=&draft_team_id=&college_id=all&conference=any&draft_pos_is_qb=Y&draft_pos_is_rb=Y&draft_pos_is_wr=Y&draft_pos_is_te=Y&draft_pos_is_e=Y&draft_pos_is_t=Y&draft_pos_is_g=Y&draft_pos_is_c=Y&draft_pos_is_ol=Y&draft_pos_is_dt=Y&draft_pos_is_de=Y&draft_pos_is_dl=Y&draft_pos_is_ilb=Y&draft_pos_is_olb=Y&draft_pos_is_lb=Y&draft_pos_is_cb=Y&draft_pos_is_s=Y&draft_pos_is_db=')\n",
    "\n",
    "# leafs = range(0, 3300, 100)\n",
    "\n",
    "# url_list = []\n",
    "\n",
    "# for i in leafs:\n",
    "#     url_list.append(base + str(i))\n",
    "    \n",
    "# test_urls = url_list[0:2]\n",
    "\n",
    "# data_points = []\n",
    "\n",
    "# count = 0\n",
    "# for i in test_urls:\n",
    "#     count +=1\n",
    "#     html = urllib.urlopen(i)\n",
    "#     soup = BeautifulSoup(html, 'html.parser')\n",
    "#     body = soup.findAll('tbody')\n",
    "#     indiv_rows = body[0].findAll('tr')\n",
    "#     print count\n",
    "#     for row in indiv_rows:\n",
    "#         inner_soup = BeautifulSoup(row.renderContents(), 'html.parser')\n",
    "#         data_points.append(inner_soup.text)\n",
    "        \n",
    "# #data_points = [i.replace('\\n', ', ') for i in data_points]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print data_points[2][:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "# define a function to get the soup\n",
    "def get_soup(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "# define a function to increment the url to the next page\n",
    "\n",
    "def next_page(base, player_count):\n",
    "    url = base+str(player_count)\n",
    "    return url\n",
    "\n",
    "# define a function that will return a list of the rows of player stats on a page\n",
    "def get_rows(soup):\n",
    "    body = soup.findAll('tbody')\n",
    "    rows = body[0].findAll('tr')\n",
    "    stat_rows = [x for x in rows if x['class']==['']]\n",
    "    return stat_rows\n",
    "\n",
    "# define a function that will strip the stats out of a row of player html data\n",
    "def strip_stats(rows):\n",
    "    for x in range(0,len(rows)):\n",
    "        player_stats = rows[x].findAll('td')\n",
    "        stats.append([z.text for z in player_stats])\n",
    "\n",
    "\n",
    "\n",
    "base = ('http://www.pro-football-reference.com/play-index/psl_finder.cgi?request=1&match=single&year_min=1999&year_max=2016&season_start=1&season_end=-1&age_min=0&age_max=99&league_id=NFL&team_id=&is_active=&is_hof=&pos_is_rb=Y&c1stat=height_in&c1comp=gt&c1val=&c2stat=fumbles_rec&c2comp=gt&c2val=&c3stat=seasons&c3comp=gt&c3val=&c4stat=rec&c4comp=gt&c4val=&c5comp=&c5gtlt=lt&c6mult=1.0&c6comp=&order_by=rush_att&draft=0&draft_year_min=1936&draft_year_max=2016&type=&draft_round_min=0&draft_round_max=99&draft_slot_min=1&draft_slot_max=500&draft_pick_in_round=0&draft_league_id=&draft_team_id=&college_id=all&conference=any&draft_pos_is_qb=Y&draft_pos_is_rb=Y&draft_pos_is_wr=Y&draft_pos_is_te=Y&draft_pos_is_e=Y&draft_pos_is_t=Y&draft_pos_is_g=Y&draft_pos_is_c=Y&draft_pos_is_ol=Y&draft_pos_is_dt=Y&draft_pos_is_de=Y&draft_pos_is_dl=Y&draft_pos_is_ilb=Y&draft_pos_is_olb=Y&draft_pos_is_lb=Y&draft_pos_is_cb=Y&draft_pos_is_s=Y&draft_pos_is_db=o&offset=')\n",
    "\n",
    "# The master function will need to have a stats and counter that increments by 100\n",
    "# and prints out how many players it has processed per loop\n",
    "def get_rb_stats(base_url, limit):\n",
    "    player_count = 0\n",
    "    while player_count <= limit:\n",
    "        url = next_page(base, player_count)\n",
    "        soup = get_soup(url)\n",
    "        rows = get_rows(soup)\n",
    "        strip_stats(rows)\n",
    "        player_count +=100\n",
    "        print '%d players processed' % player_count\n",
    "        sleep(.5)\n",
    "\n",
    "# instantiate the list that the player stats will be added to. I've yet to figure\n",
    "# out how to have this list exist inside the function and be returned by it.\n",
    "stats = []\n",
    "\n",
    "# after looking through the results of the search on pro-football-reference, this\n",
    "# upper limit will capture all of the players in the search results.\n",
    "get_rb_stats(base, 3300)\n",
    "\n",
    "# running a len on the stats column shows that we got all of the players we wanted\n",
    "print len(stats)\n",
    "# manually create the column names that we'll need for this dataframe\n",
    "rb_cols = ['rk', 'name', 'year', 'age', 'drafted', 'team', 'league',\n",
    "            'height', 'weight', 'bmi', 'games', 'starts', 'rush_atts',\n",
    "            'rush_yds', 'rush_yds_peratt', 'rush_tds', 'rush_ypg',\n",
    "            'rec_tgts', 'receptions', 'rec_yds', 'yds/rec', 'rec_tds',\n",
    "            'rec_ypg', 'ctch_pct', 'yds_per_tgt', 'fumbles', 'fumbles_recovered', 'fum_ret_yds',\n",
    "            'fum_tds', 'forced_fumbles', 'yrs', 'pro_bowl', 'all_pro', 'av']\n",
    "df = pd.DataFrame(stats, columns = rb_cols)\n",
    "\n",
    "\n",
    "# identify the numeric columns so that they can be converted before adding to sql\n",
    "numeric_columns = ['rk', 'age', 'weight', 'bmi', 'games', 'starts', 'rush_atts',\n",
    "'rush_yds', 'rush_yds_peratt', 'rush_tds', 'rush_ypg',\n",
    "'rec_tgts', 'receptions', 'rec_yds', 'yds/rec', 'rec_tds',\n",
    "'rec_ypg', 'ctch_pct', 'yds_per_tgt', 'fumbles', 'fumbles_recovered', 'fum_ret_yds',\n",
    "'fum_tds', 'forced_fumbles', 'yrs', 'pro_bowl', 'all_pro', 'av']\n",
    "\n",
    "# this loop will force the numeric columns to integers and floats depending on their nature\n",
    "for col in numeric_columns:\n",
    "    df[col] = df[col].convert_objects(convert_numeric=True)\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Checking the tail to make sure the function iterated through all the pages\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Creating a csv of the newly formed running back database\n",
    "\n",
    "df.to_csv('running_back_stats', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## I will now be creating a database in postgres in order to add\n",
    "## this dataframe as a table to perform queries on outside of python\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "engine = create_engine('postgresql://TerryONeill@localhost:5432/nfl_capstone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## this is adding the dataframe to my newly created database in psql as\n",
    "## a table named 'running_back_stats'\n",
    "df.to_sql('running_back_stats', engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
